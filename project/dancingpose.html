<!DOCTYPE html>
<html lang="en">

 <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="robots" content="index, follow">

    <title>Shanghaitech Vision and Intelligent Perception(SVIP) LAB</title>
    <meta name="description" content="">
    <link rel="alternate" type="application/rss+xml" href="/feed.xml">

    <!-- Stylesheet -->
    <link rel="stylesheet" href="/css/main.css" rel='stylesheet' type='text/css'>

    <!-- Custom styles for this template -->
    <link href="/css/offcanvas.css" rel="stylesheet">


    <!-- Google Fonts -->
    <link href='https://fonts.googleapis.com/css?family=Nunito:400,700' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,400italic,600,600italic' rel='stylesheet'
        type='text/css'>

    <!-- Favicon -->
    <link rel="shortcut icon" href="/img/small_logo.png">
</head>

<body data-spy="scroll" data-offset="80" data-target=".scrollspy" id="top">
  <div class="navigation"></div>
  <div class="news top-container">
      <div class="container-fluid">
          <div class="jumbotron">
              <h3>Liquid Warping GAN: A Unified Framework for Human Motion Imitation, Appearance Transfer and Novel
                  View Synthesis
              </h3>
              <p class="abstract">ICCV 2019</p>
              <p iclass="authors">
                  <a href="">Wen Liu*</a>,
                  <a href="">Zhixin Piao*</a>,
                  <a href="">Min Jie</a>,
                  <a href="">Wenhan Luo</a>,
                  <a href="">Lin Ma</a>,
                  <a href="">Shenghua Gao</a>
              </p>

              <p>
                  <a class="btn btn-primary" href="https://github.com/svip-lab/impersonator" target="_blank">Code</a>
                  <a class="btn btn-primary" href="/dataset/iPER_dataset.html" target="_blank">Dataset</a>
                  <a class="btn btn-primary" href="https://arxiv.org/pdf/1909.12224.pdf" target="_blank">Paper</a>
                  <a class="btn btn-primary" href="/project_img/impersonator/4701-supp.pdf" target="_blank">Supplemental Material</a>
              </p>
          </div>
        
          <div class="section">
            <h3>Abstract</h3>
            We tackle the human motion imitation, appearance transfer, and novel view synthesis within a uniﬁed
            framework, which means that the model once being trained can be used to handle all these tasks. The
            existing taskspeciﬁc methods mainly use 2D keypoints (pose) to estimate the human body structure.
            However, they only expresses the position information with no abilities to characterize the personalized
            shape of the individual person and model the limbs rotations. In this paper, we propose to use a 3D body
            mesh recovery module to disentangle the pose and shape, which can not only model the joint location and
            rotation but also characterize the personalized body shape. To preserve the source information, such as
            texture, style, color, and face identity, we propose a Liquid Warping GAN with Liquid Warping Block
            (LWB) that propagates the source information in both image and feature spaces, and synthesizes an image
            with respect to the reference. Speciﬁcally, the source features are extracted by a denoising
            convolutional auto-encoder for characterizing the source identity well. Furthermore, our proposed method
            is able to support a more ﬂexible warping from multiple sources. In addition, we build a new dataset,
            namely Impersonator (iPER) dataset, for the evaluation of human motion imitation, appearance transfer,
            and novel view synthesis. Extensive experiments demonstrate the effectiveness of our method in several
            aspects, such as robustness in occlusion case and preserving face identity, shape consistency and
            clothes details.
          </div>
        
          <div class="section">
            <h3>FrameWork Overview</h3>
            <hr>
            <center>
                <img src="http://feifantech.top:30009/pipeline.png" width="1000">
            </center>
          </div>
          
          <div class="section">
            <h3>Paper Video</h3>
            <hr>
            <center>
              <iframe width="1000" height="600" src="https://www.youtube.com/embed/nhla-Mfq2Wc" frameborder="0"
                  allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
                  allowfullscreen>
              </iframe>
            </center>

          </div>
          
          <div class="section">
            <h3>Citation</h3>
            <hr>
              If you find this useful, please cite our work as follows:
            <center>
              <img src="http://feifantech.top:30009/thumbnail.jpg" width="1000">
            </center>
            <pre>
              @InProceedings{lwb2019,
                title={Liquid Warping GAN: A Unified Framework for Human Motion Imitation, Appearance Transfer and Novel View Synthesis},
                author={Wen Liu and Zhixin Piao, Min Jie, Wenhan Luo, Lin Ma and Shenghua Gao},
                booktitle={The IEEE International Conference on Computer Vision (ICCV)},
                year={2019}
            }
            </pre>
          </div>
    </div>
  </div>

  <div class="footer"></div>
  <script src="/js/jquery.min.js"></script>
  <script src="/js/all.min.js"></script>

  <script>
    $(document).ready(function () {
        $(".footer").load("/common/footer.html");
        $(".navigation").load("/common/navigation.html");
    });
  </script>
          
</body>

</html>
